{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to fetch and parse: https://www.songkick.com/metro-areas/26330-us-sf-bay-area\n",
      "\n",
      "--- HTML Content Fetched Successfully (first 500 chars) ---\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" xmlns:og=\"http://opengraphprotocol.org/schema/\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
      "  <head prefix=\"og: http://ogp.me/ns# fb: http://www.facebook.com/2008/fbml songkick-concerts: http://ogp.me/ns/fb/songkick-concerts#\">\n",
      "\n",
      "   <meta name=\"robots\" content=\"all\">\n",
      "\n",
      "      <!-- OneTrust Cookies Consent Notice start -->\n",
      "<script id=\"onetrustcdn\" src=\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\" data-document-language=\"true\" type=\"text/javascript\" charse...\n",
      "\n",
      "\n",
      "--- Extracted 48 Events Total (after de-duplication) ---\n",
      "\n",
      "--- Found 19 Events at Specified Venues ---\n",
      "\n",
      "--- Event 1 (Filtered) ---\n",
      "Artists: ['White Denim']\n",
      "Venue:   Great American Music Hall\n",
      "Date:    Friday 16 May 2025\n",
      "\n",
      "--- Event 2 (Filtered) ---\n",
      "Artists: ['ONE OK ROCK', 'Stand Atlantic']\n",
      "Venue:   Bill Graham Civic Auditorium\n",
      "Date:    Friday 16 May 2025\n",
      "\n",
      "--- Event 3 (Filtered) ---\n",
      "Artists: ['Alison Moyet']\n",
      "Venue:   The Fillmore\n",
      "Date:    Friday 16 May 2025\n",
      "\n",
      "--- Event 4 (Filtered) ---\n",
      "Artists: ['Mall Grab']\n",
      "Venue:   1015 Folsom\n",
      "Date:    Friday 16 May 2025\n",
      "\n",
      "--- Event 5 (Filtered) ---\n",
      "Artists: ['Hurray for the Riff Raff', 'Merce Lemon']\n",
      "Venue:   The Chapel\n",
      "Date:    Friday 16 May 2025\n",
      "\n",
      "--- Event 6 (Filtered) ---\n",
      "Artists: ['Jack White']\n",
      "Venue:   The Masonic\n",
      "Date:    Saturday 17 May 2025\n",
      "\n",
      "--- Event 7 (Filtered) ---\n",
      "Artists: ['Big Gigantic', 'Emmit Fenn', 'Smoakland', 'The Funk Hunters']\n",
      "Venue:   The Midway\n",
      "Date:    Saturday 17 May 2025\n",
      "\n",
      "--- Event 8 (Filtered) ---\n",
      "Artists: ['Agalloch', 'Emperor']\n",
      "Venue:   The Warfield\n",
      "Date:    Saturday 17 May 2025\n",
      "\n",
      "--- Event 9 (Filtered) ---\n",
      "Artists: ['Matt Hansen', 'Steinza']\n",
      "Venue:   The Independent\n",
      "Date:    Saturday 17 May 2025\n",
      "\n",
      "--- Event 10 (Filtered) ---\n",
      "Artists: ['L.A. Exes', 'OK Go']\n",
      "Venue:   The Fillmore\n",
      "Date:    Sunday 18 May 2025\n",
      "\n",
      "--- Event 11 (Filtered) ---\n",
      "Artists: ['Dreamer Isioma', 'Ivri']\n",
      "Venue:   The Independent SF\n",
      "Date:    Sunday 18 May 2025\n",
      "\n",
      "--- Event 12 (Filtered) ---\n",
      "Artists: ['Blancmange', 'Midge Ure']\n",
      "Venue:   The Chapel\n",
      "Date:    Sunday 18 May 2025\n",
      "\n",
      "--- Event 13 (Filtered) ---\n",
      "Artists: ['Chris Cohen', 'Panda Bear']\n",
      "Venue:   The Chapel\n",
      "Date:    Monday 19 May 2025\n",
      "\n",
      "--- Event 14 (Filtered) ---\n",
      "Artists: ['Allison Russell', 'Kara Jackson']\n",
      "Venue:   The Fillmore\n",
      "Date:    Monday 19 May 2025\n",
      "\n",
      "--- Event 15 (Filtered) ---\n",
      "Artists: ['Rolling Quartz']\n",
      "Venue:   Great American Music Hall\n",
      "Date:    Monday 19 May 2025\n",
      "\n",
      "--- Event 16 (Filtered) ---\n",
      "Artists: ['Panda Bear']\n",
      "Venue:   The Chapel\n",
      "Date:    Tuesday 20 May 2025\n",
      "\n",
      "--- Event 17 (Filtered) ---\n",
      "Artists: ['FLO', 'Jae Stephens', 'Josh Levi']\n",
      "Venue:   The Masonic\n",
      "Date:    Tuesday 20 May 2025\n",
      "\n",
      "--- Event 18 (Filtered) ---\n",
      "Artists: ['Jane Remover']\n",
      "Venue:   The Independent\n",
      "Date:    Tuesday 20 May 2025\n",
      "\n",
      "--- Event 19 (Filtered) ---\n",
      "Artists: ['Justice']\n",
      "Venue:   Bill Graham Civic Auditorium\n",
      "Date:    Wednesday 21 May 2025\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests # For fetching HTML from a URL\n",
    "\n",
    "def extract_event_data(html_content):\n",
    "    \"\"\"\n",
    "    Extracts artists, venues, and dates from the Songkick HTML source.\n",
    "    Events on the same day at the same venue are merged, combining their artists.\n",
    "\n",
    "    Args:\n",
    "        html_content (str): The HTML content of the page.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains\n",
    "              'artists' (list of str, sorted), 'venue' (str), and 'date' (str)\n",
    "              for an event.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # Using a dictionary to store events, keyed by (date, venue_lowercase)\n",
    "    # This will help in de-duplicating events at the same venue on the same date.\n",
    "    deduplicated_events_map = {}\n",
    "\n",
    "    # The main container for event listings is a <ul> with class 'metro-area-calendar-listings'\n",
    "    # Each individual event is an <li> with class 'event-listings-element'\n",
    "    event_list_items = soup.find_all('li', class_='event-listings-element')\n",
    "\n",
    "    if not event_list_items:\n",
    "        print(\"No event listings found with class 'event-listings-element'.\")\n",
    "        print(\"Please check CSS selectors or if the page content is loaded correctly (e.g., JavaScript might be required for dynamic content).\")\n",
    "        return [] # Return empty list if no items found\n",
    "\n",
    "    for item in event_list_items:\n",
    "        # --- Extract Artists ---\n",
    "        artists_p_tag = item.find('p', class_='artists')\n",
    "        current_item_artists = []\n",
    "        if artists_p_tag:\n",
    "            strong_tag = artists_p_tag.find('strong')\n",
    "            if strong_tag:\n",
    "                primary_text = strong_tag.get_text(strip=True)\n",
    "                normalized_primary_text = primary_text.replace(' and ', ', ')\n",
    "                artists_from_strong = [\n",
    "                    artist.strip() for artist in normalized_primary_text.split(',') if artist.strip()\n",
    "                ]\n",
    "                current_item_artists.extend(artists_from_strong)\n",
    "\n",
    "            support_span = artists_p_tag.find('span', class_='support')\n",
    "            if support_span:\n",
    "                support_text = support_span.get_text(strip=True)\n",
    "                normalized_support_text = support_text.replace(' and ', ', ')\n",
    "                artists_from_support = [\n",
    "                    artist.strip() for artist in normalized_support_text.split(',') if artist.strip()\n",
    "                ]\n",
    "                current_item_artists.extend(artists_from_support)\n",
    "        \n",
    "        # Filter out any empty artist names\n",
    "        processed_artists_for_item = list(filter(None, current_item_artists))\n",
    "\n",
    "        # Only proceed if we found artists for the current item\n",
    "        if not processed_artists_for_item:\n",
    "            continue\n",
    "\n",
    "        # --- Extract Venue ---\n",
    "        venue_name = \"N/A\"\n",
    "        location_p_tag = item.find('p', class_='location')\n",
    "        if location_p_tag:\n",
    "            venue_link_tag = location_p_tag.find('a', class_='venue-link')\n",
    "            if venue_link_tag:\n",
    "                venue_name = venue_link_tag.get_text(strip=True)\n",
    "\n",
    "        # --- Extract Date ---\n",
    "        date_str = \"N/A\"\n",
    "        preceding_date_li = item.find_previous_sibling('li', class_='date-element')\n",
    "        \n",
    "        if not preceding_date_li:\n",
    "            current_sibling = item.previous_sibling\n",
    "            while current_sibling:\n",
    "                if hasattr(current_sibling, 'name') and current_sibling.name == 'li' and 'date-element' in current_sibling.get('class', []):\n",
    "                    preceding_date_li = current_sibling\n",
    "                    break\n",
    "                current_sibling = current_sibling.previous_sibling\n",
    "\n",
    "        if preceding_date_li:\n",
    "            date_time_tag = preceding_date_li.find('time', datetime=True)\n",
    "            if date_time_tag:\n",
    "                date_str = date_time_tag.get_text(strip=True)\n",
    "        \n",
    "        if date_str == \"N/A\" and item.has_attr('title') and item['title']:\n",
    "             date_str = item['title']\n",
    "        \n",
    "        # Create a key for de-duplication: (date, venue_lowercase)\n",
    "        # Using venue_name.lower() for case-insensitive venue matching for de-duplication.\n",
    "        event_key = (date_str, venue_name.lower())\n",
    "\n",
    "        if event_key in deduplicated_events_map:\n",
    "            # Event on the same date at the same venue already exists. Merge artists.\n",
    "            existing_event = deduplicated_events_map[event_key]\n",
    "            \n",
    "            # Use a set to combine current artists with existing ones to ensure uniqueness\n",
    "            combined_artists = set(existing_event['artists'])\n",
    "            combined_artists.update(processed_artists_for_item)\n",
    "            \n",
    "            # Store as a sorted list\n",
    "            existing_event['artists'] = sorted(list(combined_artists))\n",
    "        else:\n",
    "            # This is a new event (or first occurrence for this date/venue combination)\n",
    "            deduplicated_events_map[event_key] = {\n",
    "                'artists': sorted(list(set(processed_artists_for_item))), # Store unique, sorted artists\n",
    "                'venue': venue_name, # Store original venue name\n",
    "                'date': date_str\n",
    "            }\n",
    "            \n",
    "    # Convert the map of de-duplicated events back to a list\n",
    "    events_data = list(deduplicated_events_map.values())\n",
    "            \n",
    "    return events_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # URL to fetch and parse\n",
    "    target_url = \"https://www.songkick.com/metro-areas/26330-us-sf-bay-area\"\n",
    "    print(f\"Attempting to fetch and parse: {target_url}\")\n",
    "\n",
    "    # It's good practice to send some headers to mimic a browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9', # Often helps to get content in a predictable language\n",
    "    }\n",
    "\n",
    "    # Define the list of target venues (lowercase for case-insensitive matching)\n",
    "    target_venues_lower = [\n",
    "        \"the chapel\",\n",
    "        \"the independent\",\n",
    "        \"the fillmore\",\n",
    "        \"the regency ballroom\",\n",
    "        \"bill graham\", # \"Bill Graham Civic Auditorium\"\n",
    "        \"the warfield\", # Assuming this is a known venue, might need more specific name\n",
    "        \"the masonic\",\n",
    "        \"great american music hall\",\n",
    "        \"august hall\",\n",
    "        \"chase center\",\n",
    "        \"oracle park\",\n",
    "        \"the midway\",\n",
    "        \"1015 folsom\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Make the GET request to the URL\n",
    "        response = requests.get(target_url, headers=headers, timeout=10) # Added timeout for robustness\n",
    "        \n",
    "        # Check if the request was successful (status code 200-299)\n",
    "        response.raise_for_status()  # This will raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        \n",
    "        html_doc_from_url = response.text\n",
    "        \n",
    "        # --- Optional: Save HTML to a file for inspection ---\n",
    "        # with open(\"songkick_sf_bay_area.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        #     f.write(html_doc_from_url)\n",
    "        # print(\"HTML content saved to songkick_sf_bay_area.html\")\n",
    "        # --- End Optional ---\n",
    "\n",
    "        print(\"\\n--- HTML Content Fetched Successfully (first 500 chars) ---\")\n",
    "        print(html_doc_from_url[:500] + \"...\\n\")\n",
    "\n",
    "        # Call the extraction function with the fetched HTML\n",
    "        # all_extracted_data will now be de-duplicated by date and venue.\n",
    "        all_extracted_data = extract_event_data(html_doc_from_url)\n",
    "        \n",
    "        if all_extracted_data:\n",
    "            print(f\"\\n--- Extracted {len(all_extracted_data)} Events Total (after de-duplication) ---\")\n",
    "\n",
    "            # Filter events by venue\n",
    "            filtered_events = []\n",
    "            for event in all_extracted_data:\n",
    "                venue_lower = event.get('venue', '').lower()\n",
    "                if any(target_venue in venue_lower for target_venue in target_venues_lower):\n",
    "                    filtered_events.append(event)\n",
    "            \n",
    "            if filtered_events:\n",
    "                print(f\"\\n--- Found {len(filtered_events)} Events at Specified Venues ---\")\n",
    "                for i, event in enumerate(filtered_events):\n",
    "                    print(f\"\\n--- Event {i+1} (Filtered) ---\")\n",
    "                    print(f\"Artists: {event['artists']}\")\n",
    "                    print(f\"Venue:   {event['venue']}\")\n",
    "                    print(f\"Date:    {event['date']}\")\n",
    "            else:\n",
    "                print(\"\\nNo events found at the specified venues.\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\nNo data extracted from the URL.\")\n",
    "            print(\"Possible reasons:\")\n",
    "            print(\"- The website structure might have changed.\")\n",
    "            print(\"- The content might be loaded dynamically by JavaScript (requests library doesn't execute JS).\")\n",
    "            print(\"- CSS selectors in the script might need adjustment.\")\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(f\"Http Error: {errh}\")\n",
    "        print(f\"Status Code: {response.status_code if 'response' in locals() else 'N/A'}\")\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(f\"Error Connecting: {errc}\")\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(f\"Timeout Error: {errt}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"An error occurred during the web request: {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
